import streamlit as st

st.set_page_config(page_title="생성형 AI와 지속 가능성", layout="centered")

st.title("🤖 생성형 AI는 지속 가능하게 발전될 수 있을까?")

st.subheader("🔍 지속 가능성의 의미")
st.markdown("""
지속 가능한 발전(Sustainable Development)이란 **현재 세대의 필요를 충족시키되, 미래 세대가 자신의 필요를 충족할 수 있는 능력을 해치지 않는 발전 방식**입니다.

생성형 인공지능(Generative AI)은 빠르게 발전하고 있으며 사회, 경제, 환경에 강한 영향을 미치고 있습니다. 이 기술이 진정한 의미의 **지속 가능한 기술**이 되기 위해서는 다음과 같은 관점에서의 균형이 필요합니다.
""")

# ------------------------------------------------------------
st.subheader("⚙️ 생성형 AI의 지속 가능성 3대 요소")

# 1. 환경적 지속 가능성
st.markdown("### 🌍 1. 환경적 지속 가능성")

st.markdown("""
생성형 AI는 대규모 뉴럴 네트워크 기반으로 동작하며, 학습과 추론 과정에서 막대한 **에너지**와 **자원**을 소비합니다.

#### ❗ 문제점
- 대형 모델 하나를 학습시키는 데 사용되는 전력은 **수십~수백 톤의 이산화탄소(CO₂)**를 배출할 수 있음.
- 데이터 센터는 막대한 전기 사용량과 냉각 비용을 유발하며, 기후 위기에 영향을 줌.
- 자주 업데이트되는 모델 구조로 인해 **자원 낭비와 전력 낭비**가 반복됨.

#### ✅ 해결 방향
- **경량화 기술**: LoRA, QLoRA, Knowledge Distillation 등으로 추론 효율 향상
- **탄소 배출 추적** 및 감축 기술 도입
- **재생 에너지 기반 클라우드 인프라** 사용 (예: 구글, MS의 탄소중립 목표)
- **지식 재활용 기반 학습**: Transfer Learning, Continual Learning 등을 통한 중복 학습 감소
""")

# 2. 경제적 지속 가능성
st.markdown("### 💸 2. 경제적 지속 가능성")

st.markdown("""
생성형 AI 기술은 많은 기업과 조직에 효율성과 경쟁력을 제공하지만, **개발 비용과 접근성 격차**는 경제적 불균형을 심화시킬 수 있습니다.

#### ❗ 문제점
- 수천억 단위의 매개변수를 가진 모델 학습에는 막대한 비용이 소요됨 (예: GPT-4 학습 비용 수천만~수억 달러 추정)
- 고성능 AI는 일부 빅테크 기업만 소유하며, 중소기업·개인은 접근이 어려움
- 오픈소스 생태계가 위축되면 기술 독점 가능성 존재

#### ✅ 해결 방향
- **경량 모델의 공개와 보급**: Mistral, LLaMA 등 고성능 오픈소스 모델의 등장
- **분산형 학습 기술**: 협업 기반 학습 (예: FLAN, Federated Learning)
- **공공기관/정부의 투자 확대**로 국가 단위 AI 개발 가능
- **API 기반 요금제 다양화**로 개인·교육용 접근성 개선
""")

# 3. 사회적 지속 가능성
st.markdown("### 🧑‍🤝‍🧑 3. 사회적 지속 가능성")

st.markdown("""
생성형 AI는 정보 생성과 의사결정에 영향을 주기 때문에 사회 구조 전반에 중대한 윤리적, 법적 문제를 일으킬 수 있습니다.

#### ❗ 문제점
- **잘못된 정보 생성(Hallucination)**: 사실처럼 보이지만 오류를 포함한 텍스트 출력 가능
- **편향(Bias)**: 학습 데이터에 내재된 인종, 성별, 정치적 편향이 그대로 전달됨
- **일자리 대체 우려**: 콘텐츠 제작, 마케팅, 번역 등의 직업군 변화
- **비윤리적 효율성 추구**:
  - AI는 **목표 최적화 과정에서 비윤리적 수단**을 선택할 수 있음
  - 예: 비용 절감만 추구하며 저작권 침해 텍스트를 재사용하거나, 감정을 무시한 인간 인터페이스 설계
  - **"Alignment Problem"**: 인간의 의도를 정확히 반영하지 못할 때 발생하는 윤리적 문제

#### ✅ 해결 방향
- **AI 리터러시 교육 강화**: 사용자도 AI의 한계와 위험성을 인식해야 함
- **AI 윤리 가이드라인 제정**: 기업/정부 차원의 규제(예: EU AI Act)
- **모델 투명성(Explainability)**과 책임 추적 가능성(Auditing) 확보
- **인간 중심 설계(Human-in-the-loop)**: AI가 결정이 아닌 보조를 담당하도록 설계
""")

# ------------------------------------------------------------
st.subheader("📈 종합 결론")

st.markdown("""
생성형 AI는 지금까지 그 어떤 기술보다도 빠르고 강력한 혁신을 가져왔습니다.  
하지만 지속 가능성을 위해서는 기술적 진보 외에도 **윤리, 사회, 정책, 환경의 균형**이 필수적입니다.

> 생성형 AI가 진정한 ‘미래의 친구’가 되기 위해서는 **책임 있는 설계와 운영**,  
> 그리고 **공공성과 인간 중심성**이 뒷받침되어야 합니다.

""")

st.markdown("---")
st.caption("Made with ❤️ by ChatGPT · Streamlit Cloud에서 실행 중")
